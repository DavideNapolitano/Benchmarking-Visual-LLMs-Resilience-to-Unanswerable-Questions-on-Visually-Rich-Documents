{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install requirements\n",
    "\n",
    "Install requirements.txt from the repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAgngiQ8__Hf"
   },
   "source": [
    "# Starting Corruption\n",
    "Define all the parameter of the config file related to path, dataset, corruption, layout analysis and model. \n",
    "\n",
    "## Short explanation of each field:\n",
    "### Paths:\n",
    "- base_path: The root directory for relative paths.\n",
    "- augmented_dataset: Path to the JSON file containing the augmented dataset.\n",
    "- output_corrupted: Destination for the JSON file with all corrupted (unanswerable) questions.\n",
    "- output_corrupted_cleaned: Path for the cleaned version of the corrupted questions.\n",
    "- patch_saving_dir: Directory where patch files (modifications applied during corruption) are saved.\n",
    "- layout_saving_dir: Directory where layout analysis outputs are stored.\n",
    "\n",
    "### Dataset:\n",
    "- type: Indicates the dataset in use, here it's MPDocVQA or DUDE.\n",
    "- split: Specifies the data split (e.g., train) being processed.\n",
    "- dataset_json_path: File path to the original dataset JSON file.\n",
    "\n",
    "### Corruption:\n",
    "- percentage: Determines the proportion (100%) of the data to be corrupted.\n",
    "- complexity: Sets the corruption complexity level (1,2 or 3).\n",
    "- generated_sample_per_complexity_greater_than_1: Number of corrupted samples to generate for complexities higher than 1.\n",
    "- types: A set of boolean flags indicating which types of corruptions to apply (numerical, temporal, entity, location, documentâ€”all enabled).\n",
    "\n",
    "### Layout Analysis:\n",
    "- model: Specifies the layout analysis model to use, which likely helps in understanding or processing document layouts.\n",
    "\n",
    "### Model:\n",
    "- provider: Indicates the model hosting service (huggingface).\n",
    "- name: The primary model used for processing.\n",
    "\n",
    "After defining all the parameter run the main with the config path as parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uc28z2CVTiWq"
   },
   "outputs": [],
   "source": [
    "!python /corruption-scripts/corruption/main.py --config /corruption-scripts/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPC2Cr1WBGjX"
   },
   "source": [
    "# Verification step\n",
    "After the corruption process, in the config.json you can edit the parameters related to the verification.\n",
    "\n",
    "### Verification:\n",
    "- provider: The service used for verifying the corrupted outputs (gemini/openai).\n",
    "- api_key: Placeholder for the API key.\n",
    "- verification_input_file: Path to the cleaned corrupted questions that need to be verified.\n",
    "- verification_output_file: Path where the verification results will be saved.\n",
    "- verification_percentage: Indicates that all (100%) of the cleaned corrupted samples should be verified.\n",
    "- model_name: The verification model to use (gemini-2.5-flash).\n",
    "- log_file: File path to save the log output from the verification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JttLTrBYGutO",
    "outputId": "3a37c899-23d2-4724-f847-e746100874e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnswerabilityVerifier using device: cuda with provider: gemini\n",
      "Will verify 100% of questions\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739451499.763338   29011 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.\n"
     ]
    }
   ],
   "source": [
    "!python /corruption-scripts/verification/answerability_verifier.py --config /corruption-scripts/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-MDCIPLckuU"
   },
   "source": [
    "## JUST FALSE RESULTS\n",
    "Taking unanswerable questions from the verifier file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dzwD6bkctgO",
    "outputId": "683c8bf5-7940-49b7-ef9c-fbc28ddc8272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 19\n",
      "Questions with false verification: 19\n"
     ]
    }
   ],
   "source": [
    "!python /corruption-scripts/verification/just_false.py --input_file /corruption-scripts/results/MPDocVQA_unanswerable_corrupted_questions_verified.json --output_file /corruption-scripts/results/MPDocVQA_unanswerable_corrupted_questions_verified_just_false.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8OGXoZGCKjP"
   },
   "source": [
    "# VQA Models Testing\n",
    "After the verification process, VQA models can be tested on corrupted questions. \n",
    "\n",
    "You can run each model by passing the VQA_config file path as parameter.\n",
    "\n",
    "## NOTE\n",
    "The results file follows this nomenclature:\n",
    "- results_w#: prompt Explicit\n",
    "- results_w#_ocr: prompt Explicit + OCR\n",
    "- results_w#_unable: prompt None\n",
    "- results_w#_ocr_unable: prompt OCR\n",
    "\n",
    "The parameter batch_size represents the number of pages considered in the evaluation.\n",
    "\n",
    "\"unable_to_respond_aware\" set to false means that the prompt is Explicit.\n",
    "\n",
    "Following an example on how to test a model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ7CRwKt71b3"
   },
   "source": [
    "## Example: QWEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIj7Mb1cftI-"
   },
   "outputs": [],
   "source": [
    "!python /VQA_analysis/models/llm/qwen_evaluator.py --config /VQA_analysis/models/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtyBQ_OVFV98"
   },
   "source": [
    "# Answer Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In /VQA_analysis/models/results/MPDocVQA/ create a folder with each setting (results_w1, results_w1_ocr, ecc...).\n",
    "\n",
    "Inside each of them, you need to create a folder 'original' where you place the linked result files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize LLMs output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvgEbW6hAwQ0",
    "outputId": "41666f29-3069-4071-e4ed-3fff6c29afb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini model initialized successfully\n",
      "Processing: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/original/Qwen_vqa_analysis_results.json\n",
      "Saving to: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
      "Processed file saved to /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
      "Successfully processed: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/original/Qwen_vqa_analysis_results.json\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739471691.324773   59935 init.cc:232] grpc_wait_for_shutdown_with_timeout() timed out.\n"
     ]
    }
   ],
   "source": [
    "!python /VQA_analysis/models/results/MPDocVQA/unable_converter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing metrics file by adding patch_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg3LsjjiU1SH",
    "outputId": "847794de-7dc9-4be5-e489-9d093409ea2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini model initialized successfully\n",
      "Processing: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n",
      "Saving to: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/augmented/Qwen_vqa_analysis_results_converted_augmented.json\n",
      "Processed file saved to /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/augmented/Qwen_vqa_analysis_results_converted_augmented.json\n",
      "Successfully processed: /content/drive/MyDrive/Thesis/VQA_analysis/models/results/MPDocVQA/LLM/results_w1/converted/Qwen_vqa_analysis_results_converted.json\n"
     ]
    }
   ],
   "source": [
    "!python /VQA_analysis/models/results/MPDocVQA/adding_information.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrHQKWi2WKRj"
   },
   "source": [
    "Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg5PPveSvRMx",
    "outputId": "63fdecd2-5ba9-484b-bfa1-5f947bb2f3ef"
   },
   "outputs": [],
   "source": [
    "!python /VQA_analysis/models/results/result_analysis.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DPC2Cr1WBGjX"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
